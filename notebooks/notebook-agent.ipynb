{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3e737c6d-b038-4cb5-839c-51d3755fb6f6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# ServiceNow Incident Assignment Agent - Fuzzy Evaluation\n",
    "\n",
    "This notebook evaluates an AI agent using fuzzy matching for assignment group comparisons.\n",
    "It includes both exact match and fuzzy match accuracy metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2c1728ef-736f-4787-8cd2-d8cd5e7f370e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "ToDos for MVP:\n",
    "\n",
    "0. Pull Agent registration out of evaluate\n",
    "1. Agent Deployment\n",
    "2. Monitoring -> Inference Table and run drifts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "233d31c5-d852-49e9-8015-b6d6655de0fe",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Setup and Install Required Packages\n",
    "%pip install -U -qqqq mlflow>=3.0.0 langgraph==0.3.4 databricks-langchain databricks-agents uv rapidfuzz backoff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3c42c4d5-e111-4157-87fc-f7ea4fdf847f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Restart Python to ensure clean environment\n",
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2d576797-cc11-47c7-8c29-a8c7c1074c18",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from src.prompts.prompt_manager import PromptManager\n",
    "\n",
    "catalog=\"marcin_demo\"\n",
    "schema=\"demo_schema_v2\"\n",
    "prompt_manager = PromptManager(catalog=catalog, schema=schema)\n",
    "\n",
    "# register prompt\n",
    "registered = prompt_manager.register_from_yaml(\"../src/prompts/templates/classification_instruction.yaml\")\n",
    "print(f\"Registered prompts: {registered}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "06abe5bf-7b06-4041-ac3d-87bcf9337038",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Import Required Libraries and Setup Paths\n",
    "import sys\n",
    "import os\n",
    "import warnings\n",
    "import mlflow\n",
    "\n",
    "# Suppress warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Add parent directory to path to import our custom modules\n",
    "# For Jupyter notebooks, we need to handle path differently than regular Python files\n",
    "notebook_dir = os.path.dirname(os.path.abspath(os.getcwd()))\n",
    "# If we're already in the notebooks directory, go up one level\n",
    "if os.path.basename(os.getcwd()) == 'notebooks':\n",
    "    parent_dir = os.path.dirname(os.getcwd())\n",
    "else:\n",
    "    parent_dir = os.getcwd()\n",
    "\n",
    "# Ensure the parent directory is in sys.path\n",
    "if parent_dir not in sys.path:\n",
    "    sys.path.insert(0, parent_dir)\n",
    "\n",
    "print(f\"Working directory: {os.getcwd()}\")\n",
    "print(f\"Parent directory added to path: {parent_dir}\")\n",
    "\n",
    "# import mlflow\n",
    "# from databricks_langchain import VectorSearchRetrieverTool\n",
    "# from mlflow.models.resources import DatabricksFunction, DatabricksServingEndpoint\n",
    "# from unitycatalog.ai.langchain.toolkit import UnityCatalogTool\n",
    "\n",
    "# Import our evaluation modules\n",
    "# from src.metrics.fuzzy_evaluator import fuzzy_evaluator, jaro_winkler_similarity, extract_assignment_group_from_json\n",
    "# from src.evaluation.mlflow_evaluator import create_evaluation_dataset\n",
    "from src.evaluation.mlflow_evaluation import *\n",
    "\n",
    "# Import the agent\n",
    "# from model_as_code.baseline_agent import AGENT, LLM_ENDPOINT_NAME, tools, system_prompt\n",
    "\n",
    "# Configure MLflow 3 - Use consistent experiment name without timestamp\n",
    "experiment_name = \"/Users/marcin.jimenez@databricks.com/triage_recommendation\"\n",
    "mlflow.set_experiment(experiment_name)\n",
    "mlflow.set_registry_uri('databricks-uc')\n",
    "\n",
    "# MLflow 3: Setup production monitoring and comprehensive tracing\n",
    "# setup_mlflow3_production_monitoring()\n",
    "\n",
    "print(\"✅ Libraries imported with MLflow 3 GenAI capabilities\")\n",
    "print(f\"📊 MLflow Experiment: {experiment_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d3792639-3d80-42ee-a92f-63f35f2821f6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Fuzzy Matching Examples\n",
    "\n",
    "Let's demonstrate how fuzzy matching works with assignment group names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "95e9b3b4-c145-48a2-8fed-50f739893e48",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from src.evaluation.metrics.fuzzy_evaluator import fuzzy_evaluator\n",
    "\n",
    "test_pairs = [\n",
    "    (\"Apps Inpatient Core\", \"Apps Inpatient Core\"),      # Exact match\n",
    "    (\"Apps Inpatient Core\", \"Apps Inpatient-Core\"),      # Minor punctuation difference\n",
    "    (\"Apps Inpatient Core\", \"apps inpatient core\"),      # Case difference\n",
    "    (\"Apps Emergency Department\", \"Apps Emergency Dept\"),# Abbreviation\n",
    "    (\"Apps Laboratory\", \"Apps Lab\"),                     # Short form\n",
    "    (\"Epic Security\", \"Epic-Security\"),                  # Hyphen difference\n",
    "    (\"Apps Rev Cycle HIM\", \"Apps RevCycle HIM\"),          # Spacing difference\n",
    "]\n",
    "\n",
    "print(\"Fuzzy Matching Pass/Fail:\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"{'Expected':<30} {'Predicted':<30} {'Pass?':<8} {'Rationale'}\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "for expected, predicted in test_pairs:\n",
    "    # Simulate model output in the expected JSON shape\n",
    "    outputs = {\n",
    "        \"incident_number\": \"INC123\",\n",
    "        \"short_description\": \"Sample description\",\n",
    "        \"recommended_assignment_group\": predicted,\n",
    "        \"reason\": \"Example reason\",\n",
    "        \"confidence\": \"90%\"\n",
    "    }\n",
    "    # Simulate ground truth in inputs\n",
    "    inputs = {\n",
    "        \"assignment_group\": expected\n",
    "    }\n",
    "\n",
    "    feedback = fuzzy_evaluator(outputs=outputs, inputs=inputs)\n",
    "    print(f\"{expected:<30} {predicted:<30} {str(feedback.value):<8} {feedback.rationale}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "03cb0e10-2f2f-4c29-928e-474bc4edb74c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Data Preview and Agent Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "38ade789-3ac8-4d9f-be3b-e1d224c120e3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "SELECT number as incident_number, assignment_group\n",
    "FROM prod_silver.dts_ops.servicehub_task_displayvalue\n",
    "LIMIT 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dd0ba5a0-f3a0-4253-aa66-33c56b36402a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "SELECT number as incident_number, assignment_group\n",
    "FROM prod_silver.dts_ops.servicehub_task_displayvalue\n",
    "WHERE number ='INC4463480'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4d88e29c-9938-493c-b0b1-d2cddea55e13",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Test Agent with Single Incident\n",
    "import json\n",
    "from src.agents.triage_agent import AGENT\n",
    "\n",
    "LLM_ENDPOINT_NAME = \"databricks-meta-llama-3-3-70b-instruct\"\n",
    "\n",
    "mlflow.models.set_model(AGENT)\n",
    "\n",
    "response = AGENT.predict({\n",
    "    \"input\": [\n",
    "        {\"role\": \"user\", \"content\": \"INC4463480\"}\n",
    "    ]\n",
    "})\n",
    "# response = AGENT.predict({\"messages\": [{\"role\": \"user\", \"content\": \"INC4463480\"}]})\n",
    "print(\"Agent Response (agent type: %s, response type: %s)\" % (type(AGENT), type(response)))\n",
    "print(response.output[-1].content[0]['text'])\n",
    "\n",
    "# Extract and show the assignment group\n",
    "assignment_group = json.loads(response.output[-1].content[0]['text'])[\"recommended_assignment_group\"]\n",
    "print(f\"\\nExtracted Assignment Group: {assignment_group}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1221ccc1-999a-4f75-a807-fb461b52a9fa",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Create Evaluation Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9a26ddc6-2d9c-4f16-b3ac-2168ad6f18b5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Create Evaluation Dataset\n",
    "from src.evaluation.mlflow_evaluation import create_evaluation_dataset\n",
    "eval_dataset = create_evaluation_dataset(\n",
    "    spark=spark,\n",
    "    table_path=\"prod_silver.dts_ops.servicehub_task_displayvalue\",\n",
    "    sample_size=100\n",
    ")\n",
    "\n",
    "print(f\"\\nCreated evaluation dataset with {len(eval_dataset)} incidents\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "abf491fb-cd68-4927-a571-d44972297e53",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "eval_dataset[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "87397895-3928-433a-b25d-8547ec51f1c0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(eval_dataset['targets'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9b4f35e8-a1d4-4f5c-b0a6-f036942d5403",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Register Agent into UC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "15b7b813-f8b4-450b-bc22-88f7027600a1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "agent_path=\"../src/agents/triage_agent.py\"\n",
    "agent_config={\n",
    "    \"endpoint_name\": \"databricks-meta-llama-3-1-8b-instruct\",\n",
    "    \"temperature\": 0.1,\n",
    "    \"max_tokens\": 500,\n",
    "    \"prompt_template\": \"classification_instruction\"\n",
    "}\n",
    "resources = [\n",
    "    DatabricksServingEndpoint(endpoint_name=agent_config.get(\"endpoint_name\"))\n",
    "] if agent_config.get(\"endpoint_name\") else []\n",
    "input_example={\n",
    "    \"input\": [\n",
    "        {\"role\": \"user\", \"content\": \"INC0936934\"}\n",
    "    ]\n",
    "}\n",
    "requirements=[\n",
    "    \"mlflow>=3.0.0\",\n",
    "    \"databricks-sdk[openai]\",\n",
    "    \"databricks-agents\",\n",
    "    \"databricks-langchain\",\n",
    "    \"langgraph\",\n",
    "    \"backoff\"\n",
    "]\n",
    "\n",
    "model_info = mlflow.pyfunc.log_model(\n",
    "    name=\"dts_ops_triage_agent-v1\",\n",
    "    python_model=agent_path,\n",
    "    model_config=agent_config,\n",
    "    resources=resources,\n",
    "    input_example=input_example,\n",
    "    pip_requirements=requirements,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f01170f5-8137-49e6-b6e3-436c92a0e8f1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Run Agent Evaluation with Fuzzy Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e98791ff-abc6-402a-90c2-9227c2006a64",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Run Evaluation with MLflow 3 GenAI Capabilities\n",
    "from src.evaluation.mlflow_evaluation import evaluate_agent\n",
    "print(\"Starting evaluation with MLflow 3 GenAI features...\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# # End any existing MLflow runs before starting a new one\n",
    "# try:\n",
    "#     mlflow.end_run()\n",
    "#     print(\"Ended existing MLflow run\")\n",
    "# except:\n",
    "#     pass\n",
    "\n",
    "# Suppress the detailed DataFrame output\n",
    "import warnings\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    \n",
    "    # Use MLflow 3 evaluation with GenAI capabilities\n",
    "    # Note: We're skipping the fuzzy metric in extra_metrics due to MLflow compatibility issues\n",
    "    # but it will be calculated and logged separately\n",
    "    model_info, eval_results = evaluate_agent(\n",
    "        model_info=model_info,\n",
    "        # judge_endpoint=\"databricks-meta-llama-3-1-70b-instruct\",\n",
    "        eval_dataset=eval_dataset,\n",
    "        experiment_name=experiment_name,\n",
    "        # include_builtin_metrics=True,  # Disable for now to avoid conflicts\n",
    "        # include_custom_metrics=True,   # Will calculate fuzzy matching separately\n",
    "        # genai_evaluators=[],  # Empty list to avoid additional evaluators\n",
    "    )\n",
    "\n",
    "# Display summary\n",
    "if eval_results:\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"MLFLOW 3 EVALUATION COMPLETE\")\n",
    "    print(\"=\"*50)\n",
    "    print(f\"\\n✅ Evaluated {len(eval_dataset)} incidents\")\n",
    "    print(\"✅ Full tracing captured for all LLM interactions\")\n",
    "    print(\"✅ Results logged to MLflow with comprehensive metrics\")\n",
    "    \n",
    "    # Display the MLflow experiment URL\n",
    "    print(f\"\\n🔗 View results in MLflow UI:\")\n",
    "    print(f\"   Experiment: {experiment_name}\")\n",
    "else:\n",
    "    print(\"⚠️ No evaluation results available\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": {
    "hardware": {
     "accelerator": null,
     "gpuPoolId": null,
     "memory": null
    }
   },
   "dashboards": [],
   "environmentMetadata": null,
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 5094125788044841,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 2
   },
   "notebookName": "notebook-agent",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
